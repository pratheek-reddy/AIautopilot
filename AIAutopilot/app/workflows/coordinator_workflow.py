"""
Coordinator Workflow Module.

This module implements the core workflow orchestration logic for the AI Autopilot system.
It manages the execution flow between different specialist agents (diagnostic, automation, writer)
and handles state transitions, error recovery, and dynamic plan modifications based on agent outputs.

Key features:
- Workflow state management
- Agent coordination and execution
- Dynamic plan modification based on diagnostic results
- Error handling and retry logic
- Confidence-based branching
"""

from langgraph.graph import Graph, StateGraph
from langchain.schema.runnable import RunnablePassthrough
from app.agents.coordinator_agent import CoordinatorAgent
from app.agents.diagnostic_agent import DiagnosticAgent
from app.agents.automation_agent import AutomationAgent
from app.agents.writer_agent import WriterAgent
from app.models import Plan, PlanStep, Diagnosis, Script
from pydantic import BaseModel
from typing import Optional, Any, Dict, List
from app.core.config import settings
from app.workflows.writer_graph import WriterGraph
from app.workflows.writer_states import WriterGraphState, ContentState, ContentMetadata
from app.core.writer_config import WriterGraphConfig, ContentFormat
from datetime import datetime
from openai import OpenAI
import logging

logger = logging.getLogger("workflow_debug")

# Threshold below which diagnostic results are considered low confidence
# This affects workflow branching and plan modification
LOW_CONFIDENCE_THRESHOLD = 70

# Thresholds for context summarization
ORIGINAL_REQUEST_SUMMARIZATION_THRESHOLD = 1500  # characters
SUMMARY_MAX_WORDS = 100

class WorkflowState(BaseModel):
    """
    State model for tracking workflow execution progress and results.

    This model maintains the complete state of a workflow execution, including
    the execution plan, current progress, results from different agents, and
    error handling information.

    Attributes:
        request: The original user request being processed.
        plan: The execution plan generated by the coordinator.
        current_step: Index of the current step being executed.
        diagnosis: Results from the diagnostic agent if any.
        script: Generated script from the automation agent if any.
        output: Formatted output from the writer agent if any.
        completed: Flag indicating if workflow has completed.
        failed: Flag indicating if workflow has failed.
        error: Error message if workflow failed.
        retry_counts: Counter for retry attempts per step.
    """
    request: str
    plan: Optional[Plan] = None
    current_step: int = 0
    diagnosis: Optional[Diagnosis] = None
    script: Optional[Script] = None
    output: Optional[str] = None
    completed: bool = False
    failed: bool = False
    error: Optional[str] = None
    retry_counts: Dict[int, int] = {}

def truncate_text(text: str, max_length: int) -> str:
    """
    Truncates text to a specified maximum length, adding ellipsis if truncated.

    Args:
        text: The input text to truncate.
        max_length: Maximum allowed length for the text.

    Returns:
        The truncated text with ellipsis if truncated, or original text if within limit.
    """
    if len(text) > max_length:
        return text[:max_length] + "..."
    return text

def get_contextual_summary(text: str, max_summary_words: int = SUMMARY_MAX_WORDS) -> str:
    """
    Generate a concise summary of the input text using LLM.

    This function uses a cost-effective LLM model (gpt-3.5-turbo) to create
    an intelligent summary of long input text, preserving key information
    while reducing length.

    Args:
        text: The input text to summarize.
        max_summary_words: Target word count for the summary.

    Returns:
        A concise summary of the input text.

    Raises:
        Exception: If LLM summarization fails.
    """
    try:
        client = OpenAI(api_key=settings.OPENAI_API_KEY)
        summary_prompt = (
            f"Concisely summarize the following user request in approximately {max_summary_words} words, "
            f"focusing on the main goal and key entities. Preserve any specific technical details, "
            f"parameters, or requirements mentioned. Original request: \"{text}\""
        )

        response = client.chat.completions.create(
            model="gpt-3.5-turbo",  # Cost-effective model for summarization
            messages=[
                {"role": "system", "content": "You are an expert at concisely summarizing technical requests while preserving key details."},
                {"role": "user", "content": summary_prompt}
            ],
            max_tokens=max_summary_words * 2,  # Allow buffer for token count
            temperature=0.3  # Lower temperature for more factual summary
        )
        
        summary = response.choices[0].message.content.strip()
        logger.info(f"Successfully generated summary of length {len(summary)} chars")
        return summary
    except Exception as e:
        logger.error(f"Failed to generate LLM summary: {e}")
        raise

def create_coordinator_graph() -> Graph:
    """
    Creates and configures the workflow coordination graph.

    This function initializes all necessary agents, sets up the workflow graph structure,
    and defines the coordination logic between different specialist agents.

    Returns:
        A compiled Graph object ready for workflow execution.
    """
    # Initialize specialist agents that will handle different aspects of the workflow
    coordinator = CoordinatorAgent()
    diagnostic = DiagnosticAgent()
    automation = AutomationAgent()
    writer = WriterAgent()
    
    # Initialize the writer's specialized workflow graph
    writer_graph = WriterGraph(WriterGraphConfig())
    compiled_writer_graph = writer_graph.graph.compile()

    def coordinator_runnable(state: WorkflowState) -> WorkflowState:
        """
        Core workflow coordination function that manages execution flow between agents.

        This function:
        1. Manages the workflow state and progression
        2. Coordinates between different specialist agents
        3. Handles error recovery and retries
        4. Implements dynamic plan modification based on agent results

        Args:
            state: Current workflow state containing execution progress and results.

        Returns:
            Updated workflow state after executing the current step.

        Raises:
            Exception: If an agent fails to process its task after max retries.
        """
        # Initial plan creation if not exists
        if not state.plan:
            plan = coordinator.run(state.request)
            state.plan = plan
            return state

        # Early return if workflow is already complete or failed
        if state.failed or state.completed:
            return state

        # Setup step execution
        max_retries = 3
        step = state.current_step
        if step >= len(state.plan.steps):
            state.completed = True
            return state

        # Get current step details and prepare for execution
        agent_type = state.plan.steps[step].agent_type
        if state.retry_counts is None:
            state.retry_counts = {}
        retry_count = state.retry_counts.get(step, 0)
        
        try:
            # Prepare focused input for the specialist agent
            current_step_details = state.plan.steps[step]
            step_description = current_step_details.description
            
            # Get contextual summary of the original request if it's too long
            contextual_summary_of_request = state.request
            if len(state.request) > ORIGINAL_REQUEST_SUMMARIZATION_THRESHOLD:
                try:
                    contextual_summary_of_request = get_contextual_summary(state.request)
                    logger.info("Original request summarized for broader context.")
                except Exception as e:
                    logger.error(f"Failed to summarize original request, falling back to truncation: {e}")
                    contextual_summary_of_request = truncate_text(state.request, 1000)
            else:
                # If not long enough to warrant summarization, still apply simple truncation if needed
                contextual_summary_of_request = truncate_text(state.request, 1000)

            focused_input_for_agent = f"Specific task for this step: \"{step_description}\".\n\nOverall context from original request: \"{contextual_summary_of_request}\""
            
            # Route to appropriate specialist agent based on type
            if agent_type == "diagnostic":
                diagnosis = diagnostic.run(focused_input_for_agent)
                state.diagnosis = diagnosis
                
                # Handle case where no problem is identified
                if state.diagnosis and not state.diagnosis.problem_identified:
                    logger.info("DiagnosticAgent reported no problem identified. Modifying plan to skip to reporting/end.")
                    
                    # Prepare detailed no-problem report
                    no_problem_message = (
                        f"Diagnostic assessment complete: No specific problem requiring intervention was identified.\n\n"
                        f"Details:\n"
                        f"- Initial concern: {state.diagnosis.problem}\n"
                        f"- Finding: {state.diagnosis.root_cause}\n"
                        f"- Confidence: {state.diagnosis.confidence}%\n"
                        f"- Additional Information: {state.diagnosis.additional_info or 'None provided'}"
                    )
                    state.output = no_problem_message
                    
                    # Modify plan to skip unnecessary steps
                    new_plan_steps = [current_step_details]
                    next_writer_step_found = False
                    
                    # Look for existing writer step or create new one
                    for i in range(step + 1, len(state.plan.steps)):
                        if state.plan.steps[i].agent_type == "writer":
                            updated_writer_step = PlanStep(
                                step_number=new_plan_steps[-1].step_number + 1,
                                description=f"Report diagnostic findings: No problem requiring intervention was identified. Original task: {state.plan.steps[i].description}",
                                agent_type="writer"
                            )
                            new_plan_steps.append(updated_writer_step)
                            next_writer_step_found = True
                            break
                    
                    if not next_writer_step_found:
                        new_writer_step = PlanStep(
                            step_number=new_plan_steps[-1].step_number + 1,
                            description="Draft a report explaining that no problem requiring intervention was identified",
                            agent_type="writer"
                        )
                        new_plan_steps.append(new_writer_step)
                    
                    state.plan.steps = new_plan_steps
                    state.plan.summary = "Concluded after diagnosis: No problem identified."
                
                # Handle low confidence diagnostic results
                elif state.diagnosis and state.diagnosis.confidence is not None and state.diagnosis.confidence < LOW_CONFIDENCE_THRESHOLD:
                    logger.info(f"Low diagnostic confidence ({state.diagnosis.confidence} < {LOW_CONFIDENCE_THRESHOLD}). Altering plan to report and conclude.")
                    
                    # Prepare detailed low-confidence report
                    low_confidence_message = (
                        f"The diagnostic assessment resulted in a low confidence score of {state.diagnosis.confidence}. "
                        f"Initial findings suggest the root cause might be '{state.diagnosis.root_cause or 'not clearly identified'}' "
                        f"based on evidence: {', '.join(state.diagnosis.evidence) if state.diagnosis.evidence else 'not available'}. "
                        f"It's recommended to manually review the situation or provide more specific details for a clearer diagnosis."
                    )
                    state.output = low_confidence_message
                    
                    # Modify plan to handle low confidence case
                    current_step_number = current_step_details.step_number
                    new_writer_step = PlanStep(
                        step_number=current_step_number + 1,
                        description=f"Draft a communication about the inconclusive diagnosis (confidence: {state.diagnosis.confidence}%). Include initial findings and recommendations for manual review.",
                        agent_type="writer"
                    )
                    
                    state.plan.steps = state.plan.steps[:state.current_step + 1] + [new_writer_step]
                    state.plan.summary = "Report inconclusive diagnosis due to low confidence."
                
            elif agent_type == "automation":
                # Execute automation task
                request_dict = {"request": focused_input_for_agent}
                script = automation.run(request_dict)
                state.script = script

            elif agent_type == "writer":
                # Prepare context for writer based on previous results
                writer_context = focused_input_for_agent
                
                # Use appropriate context based on workflow state
                if state.output and ("no problem identified" in state.output or "low confidence score" in state.output):
                    writer_context = state.output
                elif "summarize diagnosis" in step_description.lower() and state.diagnosis:
                    writer_context += f"\n\nDiagnosis results: {state.diagnosis}"
                elif "summarize script" in step_description.lower() and state.script:
                    writer_context += f"\n\nScript details: {state.script}"
                
                # Calculate content metrics
                actual_character_count = len(writer_context)
                actual_word_count = len(writer_context.split())
                
                # Initialize writer state with metadata
                writer_state = WriterGraphState(
                    current_node="content_analyzer",
                    content_state=ContentState(
                        original_content=writer_context,
                        content_type="text",
                        structure={},
                        processing_status="pending",
                        metadata=ContentMetadata(
                            content_type="text",
                            word_count=actual_word_count,
                            character_count=actual_character_count,
                            language="en",
                            created_at=datetime.utcnow(),
                            modified_at=datetime.utcnow(),
                            format=ContentFormat.MARKDOWN
                        )
                    )
                )
                
                # Execute writer workflow
                result = compiled_writer_graph.invoke(writer_state)
                output_state = result.get("output_state")
                formatted_content = output_state.formatted_content if output_state else None
                state.output = formatted_content

            else:
                # Handle unknown agent type
                state.error = f"Unknown agent type: {agent_type}"
                state.failed = True
                return state

            # Update workflow progress
            state.current_step += 1
            if state.current_step >= len(state.plan.steps):
                state.completed = True
            return state

        except Exception as e:
            # Handle execution errors with retry logic
            retry_count += 1
            state.retry_counts[step] = retry_count
            if retry_count >= max_retries:
                state.failed = True
                state.error = f"Step {step} ({agent_type}) failed after {max_retries} retries: {e}"
                state.completed = True
            return state

    # Configure the workflow graph structure
    graph = StateGraph(WorkflowState)
    graph.add_node("coordinator", coordinator_runnable)
    graph.add_node("end", lambda state: state)
    graph.add_conditional_edges(
        "coordinator",
        plan_condition,
        {
            "coordinator": "coordinator",
            "end": "end"
        }
    )
    graph.set_entry_point("coordinator")
    return graph.compile()

def plan_condition(state: WorkflowState) -> str:
    """
    Determines the next node in the workflow graph based on current state.

    Args:
        state: Current workflow state.

    Returns:
        String indicating the next node to transition to ('end' or 'coordinator').
    """
    if state.completed or state.failed or state.current_step >= len(state.plan.steps):
        return "end"
    return "coordinator"
